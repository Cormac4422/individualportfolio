<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>individualportfolio</title>
</head>
<body>
  <h1>Week 4, Social Media & the Web - Principles within "A Contract for the Web" / Responses to "The Internet's Own Boy"</h1>
  
  <p>Based on Eli Pariser's TED Talk and the Contract for the Web, two main ideas are deeply connected. Principle 5: Protect people's privacy and data. Principle 8: Build kind and strong online communities. These ideas support each other. One makes the other possible. The "filter bubble" shows the main problem. Websites use your personal data to decide what you see. This often hurts public conversation. When platforms secretly personalize your feed, it breaks trust. It also means people no longer share the same facts. Communities inside these separate bubbles cannot have real discussion, because everyone sees a different version of the internet. Other things, like local laws or technology, also shape your online experience. But the constant data collection that creates filter bubbles hurts both principles. It turns private information into a product and splits communities apart. Protecting privacy is about giving people control. When users trust that their data is safe, they are more likely to be themselves online. This helps create communities based on trust, not on being watched. Both principles are about this control. Principle 5 gives you control over your information. Principle 8 makes sure the online space deserves that trust. Without privacy, communities can be easily manipulated. Without respectful talk, privacy loses its meaning. The goal is to build websites and apps that value both ideas. To make real change, companies must be responsible and users must choose platforms that follow these rules.</p>p>

  <h1>Response to - Should All Archives Be Open Access?</h1>

  <p>Reading Rev's article shows that open archives are not a simple choice. His three main points explain why. First, opening archives can hurt people. Old records often have private details or painful stories. Putting them online could cause harm or shame to those people or their families. Second, a document can mean different things in different places. What is safe in one country might be dangerous in another. Once something is online, it can be taken out of context or used in the wrong way. Third, it is hard to open everything. There are costs, copyright laws, and some places do not have good internet access. Not every archive can put its records online fairly. I think we should open archives carefully. It helps researchers and learners when information is shared. But we must always protect people's privacy and safety first.</p>

  <h1>What is Artificial Intelligence?</h1>
  <p>Joy Buolamwini’s TED Talk shows that Artificial Intelligence is not what many people think. It is a system built by humans to find patterns in data. It does not see or understand the world. It only sees the information we give it. Her talk proves AI is not actually intelligent. She showed how face-scanning software could not detect her face until she wore a white mask. The AI was trained mostly on light-skinned male faces so it failed with others. This shows AI does not think. It only repeats the patterns and even the mistakes from its data. Her talk made me worry about the coming AI revolution. This technology is already used in important places like police work and job applications. If the data has human bias the AI will copy that bias and make unfair decisions on a huge scale. This is dangerous. The revolution will not be managed by machines. It will be shaped by our choices. We must demand that the people who build AI use fair and complete data. We must make rules to keep it accountable. AI is a powerful tool but it is our responsibility to make sure it helps people and does not harm them.</p>

  <h1>Responses to Anatomy of an AI System</h1>
  <p>Reading the article changed how I see AI. I thought it was just computer code or a smart program in the cloud. The article shows it is a physical thing built from the earth with a heavy human and environmental cost. It starts with people mining metals and minerals from the ground. This work is often dangerous. These raw materials are shipped around the world to factories. Workers assemble them into phones and smart speakers. The finished devices are shipped again to stores and our homes. Then we become part of the system. When we talk to a voice assistant or use a search engine we are not just consumers. We are providing free labor. Our voices and questions are the data that trains the AI to be smarter. The article says we are users, workers, and products all at the same time. This idea is powerful. It makes me look at the technology in my house differently. My smart speaker is not just a helpful gadget. It is the endpoint of a long chain of work and resource use. The article was an important eye opener. It shows the full story of AI from the ground to our living rooms. To talk about AI ethics or the future we must first understand this real physical system and its true cost.</p>

  <h1>What potential applications for VR, AR and XR do you envisage in future?</h1>
  <p>I think VR, AR and XR will be used in many helpful ways in the future. In education these tools can make learning real. Students could use VR to visit ancient Rome or walk inside a human heart. AR could make a textbook come to life showing 3D models right on the page. In healthcare the benefits could be great. Surgeons could practice operations in VR many times with no risk. During real surgery AR could show a patient's scans floating in the air helping the surgeon see exactly where to cut. This could save lives. These tools could also change how we work and connect. Instead of a video call you could put on a headset and sit in a virtual room with coworkers from around the world. You could share and change 3D designs together as if they were real objects on a table. However there are risks. If these worlds become too good people might not want to leave them. We must use VR and AR to improve real life not escape from it. The goal should be to help us learn, heal and work better, not to replace the people and places around us.</p>

  <h2>References</h2>
  <p>World Wide Web Foundation. Contract for the Web. 2019.</p>
<p>Pariser, Eli. “Beware Online ‘Filter Bubbles.’” TED, 2011.</p>
<p>Knappenberger, Brian. The Internet's Own Boy: The Story of Aaron Swartz. 2014.</p>
<p>Buolamwini, Joy. “How I’m Fighting Bias in Algorithms.” TED, 2018.</p>
<p>Crawford, Kate, and Vladan Joler. Anatomy of an AI System. 2018.</p>
</body>
</html>



